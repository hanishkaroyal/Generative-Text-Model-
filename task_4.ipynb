{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation using GPT\n",
    "This notebook demonstrates how to use a pre-trained GPT model to generate coherent paragraphs based on user prompts. We'll utilize the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ed7f2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a636b6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf1f6e0",
   "metadata": {},
   "source": [
    "## Load Pre-trained GPT Model and Tokenizer\n",
    "We'll use the `gpt2` model from Hugging Face's model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca7c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ff053",
   "metadata": {},
   "source": [
    "## Define Text Generation Function\n",
    "This function generates text based on a given prompt.\n",
    "\n",
    "Generate text using the model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate text from.\n",
    "        max_length (int): Maximum length of the generated text.\n",
    "        temperature (float): Sampling temperature.\n",
    "        top_k (int): Top-k sampling.\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a803306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=200, temperature=0.7, top_k=50):\n",
    "    \n",
    "    # Encode the input prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405b173",
   "metadata": {},
   "source": [
    "## Test the Text Generation Function\n",
    "Provide a prompt to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733e6f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Text: Artificial intelligence is transforming the world by\n",
      "\n",
      "Generated Text:\n",
      "Artificial intelligence is transforming the world by accelerating the evolution of life. The human mind has changed, becoming a vast entity that has grown exponentially. It is now the size of a small football field.\n",
      "\n",
      "The world has become a dystopian world. It is a world where everyone is enslaved to a certain set of laws, and all are enslaved by evil powers, and there are no end in sight.\n",
      "\n",
      "I know that some of you may be aware of the way that technology has been used to create a whole new type of world. The world we live in now is a world where a person can choose to be anything they want, and they can always do with as much freedom as they please. That's not that different than the world\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Artificial intelligence is transforming the world by\"\n",
    "print(\"Prompt Text: \" + prompt)\n",
    "# Generate text\n",
    "generated_text = generate_text(prompt, max_length=150, temperature=0.7, top_k=50)\n",
    "print(\"\\nGenerated Text:\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
